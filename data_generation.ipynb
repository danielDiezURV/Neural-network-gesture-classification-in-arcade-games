{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5cc0346",
   "metadata": {},
   "source": [
    "# Gesture Data Generation\n",
    "\n",
    "This notebook is designed to capture images of hand gestures from a webcam. The captured images will be used to train a gesture recognition model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a5384d",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "In the next cell, you can configure the parameters for the data capture process.\n",
    "\n",
    "- `num_screenshots`: The total number of images to capture for the gesture.\n",
    "- `capture_rate`: The time delay (in seconds) between each screenshot.\n",
    "- `gesture_name`: The name of the gesture you are capturing (e.g., \"point_up\", \"fist\"). This will be used as the folder name and the base name for the image files.\n",
    "- `folder_location`: The directory where the captured images will be saved. It is automatically set based on the `gesture_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfed6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "# --- Configuration ---\n",
    "num_screenshots = 500  # Number of images to capture\n",
    "capture_rate = 0.05  # Seconds between captures\n",
    "gesture_name = \"hand_straight\"  # Name of the gesture (e.g., \"fist\", \"point_right\")\n",
    "\n",
    "# --- File and Folder Setup ---\n",
    "base_folder = \"data/gestures\"\n",
    "folder_location = os.path.join(base_folder, gesture_name)\n",
    "picture_name = gesture_name\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(folder_location, exist_ok=True)\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\" - Number of screenshots: {num_screenshots}\")\n",
    "print(f\" - Capture rate: {capture_rate} seconds\")\n",
    "print(f\" - Gesture name: '{gesture_name}'\")\n",
    "print(f\" - Saving to: '{folder_location}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7152acaa",
   "metadata": {},
   "source": [
    "## Image Capture\n",
    "\n",
    "Run the following cell to start the image capture process. A window will appear showing your webcam feed.\n",
    "\n",
    "- **Position your hand** to make the desired gesture.\n",
    "- Press the **'s'** key to start the automated capture.\n",
    "- The window will display a countdown of the images being taken.\n",
    "- Press the **'q'** key at any time to stop the capture and close the window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1a8b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import os\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "count = len(os.listdir(folder_location))\n",
    "\n",
    "screenshots_taken = 0\n",
    "capturing = False\n",
    "last_capture_time = 0\n",
    "window_name = 'Data Generation'\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    display_frame = frame.copy()\n",
    "\n",
    "    if not capturing:\n",
    "        cv2.putText(display_frame, \"Press 's' to start capturing\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    else:\n",
    "        cv2.putText(display_frame, f\"Capturing... {screenshots_taken}/{num_screenshots}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    \n",
    "    cv2.putText(display_frame, \"Press 'q' to quit\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow(window_name, display_frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('s'):\n",
    "        if not capturing:\n",
    "            print(\"Starting capture...\")\n",
    "            capturing = True\n",
    "            last_capture_time = time.time()\n",
    "\n",
    "    if capturing:\n",
    "        current_time = time.time()\n",
    "        if current_time - last_capture_time >= capture_rate:\n",
    "            if screenshots_taken < num_screenshots:\n",
    "                img_name = os.path.join(folder_location, f\"{picture_name}_{count:03d}.jpg\")\n",
    "                cv2.imwrite(img_name, frame)\n",
    "                print(f\"Saved {img_name}\")\n",
    "                count += 1\n",
    "                screenshots_taken += 1\n",
    "                last_capture_time = current_time\n",
    "            else:\n",
    "                print(\"Capture complete.\")\n",
    "                break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9ef4f0",
   "metadata": {},
   "source": [
    "## Dataset Generation\n",
    "\n",
    "The following cell processes the images captured in the previous steps. It uses `MediaPipe` to detect hand landmarks in each image, normalizes the landmark data, and then compiles it into a structured dataset.\n",
    "\n",
    "The final dataset will have two columns:\n",
    "- `GESTURE_ID`: An integer identifier for each gesture (based on the folder name).\n",
    "- `LANDMARKS`: The normalized 60-element vector (20 landmarks * 3 coordinates) representing the hand gesture.\n",
    "\n",
    "This dataset is then saved to a CSV file for use in model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0abc6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.gesture_controller.data_preprocessor import DataPreprocessor\n",
    "from src.gesture_controller.gesture_detector import GestureDetector\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "gestures_folder = \"data/gestures\"\n",
    "output_csv_file = \"data/gestures_dataset.csv\"\n",
    "key_bindings_file = \"config/key_bindings_default.json\"\n",
    "\n",
    "# --- Initialization ---\n",
    "# We set max_hands to 1 because we are analyzing images of a single gesture\n",
    "detector = GestureDetector(max_hands=1, min_detection_confidence=0.5)\n",
    "data_preprocessor = DataPreprocessor()\n",
    "dataset = []\n",
    "\n",
    "# --- Data Processing ---\n",
    "if not os.path.isdir(gestures_folder):\n",
    "    print(f\"Error: Gestures folder not found at '{gestures_folder}'\")\n",
    "else:\n",
    "    # Get the list of gesture subdirectories and create a mapping to integer IDs\n",
    "    gesture_folders = sorted([f for f in os.listdir(gestures_folder) if os.path.isdir(os.path.join(gestures_folder, f))])\n",
    "    gesture_map = {name: i for i, name in enumerate(gesture_folders)}\n",
    "\n",
    "    print(\"Processing gestures...\")\n",
    "    print(f\"Found gestures: {gesture_map}\")\n",
    "\n",
    "    # Iterate over each gesture folder\n",
    "    for gesture_name, gesture_id in gesture_map.items():\n",
    "        folder_path = os.path.join(gestures_folder, gesture_name)\n",
    "        print(f\"\\nProcessing folder: {folder_path}\")\n",
    "\n",
    "        # Get a sorted list of images to process them in a consistent order\n",
    "        image_files = sorted([f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "\n",
    "        # Iterate over each image in the folder\n",
    "        for image_name in image_files:\n",
    "            image_path = os.path.join(folder_path, image_name)\n",
    "            \n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"Warning: Could not read image {image_path}\")\n",
    "                continue\n",
    "\n",
    "            # Process the frame to find hands\n",
    "            detector.process_frame(image)\n",
    "            \n",
    "            # Get hand vectors (we expect only one hand)\n",
    "            left_hand, right_hand = detector.get_hand_vectors()\n",
    "            hand_vector = left_hand or right_hand\n",
    "\n",
    "            if hand_vector:\n",
    "                # Normalize the landmarks\n",
    "                normalized_landmarks = data_preprocessor.process(hand_vector)\n",
    "                \n",
    "                if normalized_landmarks is not None:\n",
    "                    # Append the gesture ID and the flattened list of landmarks\n",
    "                    dataset.append([gesture_id, normalized_landmarks.tolist()])\n",
    "            else:\n",
    "                print(f\"Warning: No hand detected in {image_path}\")\n",
    "\n",
    "    # --- Generate Default Key Bindings Configuration ---\n",
    "    key_bindings_config = {}\n",
    "    for gesture_name, gesture_id in gesture_map.items():\n",
    "        key_bindings_config[str(gesture_id)] = {\n",
    "            \"gesture\": gesture_name,\n",
    "            \"keys\": [],\n",
    "            \"behavior\": \"\"\n",
    "        }\n",
    "    \n",
    "    # Save the default key bindings configuration\n",
    "    with open(key_bindings_file, 'w') as f:\n",
    "        json.dump(key_bindings_config, f, indent=2)\n",
    "    \n",
    "    # --- Create and Save DataFrame ---\n",
    "    if dataset:\n",
    "        # Create a DataFrame from the collected data\n",
    "        df = pd.DataFrame(dataset, columns=[\"GESTURE_ID\", \"LANDMARKS\"])\n",
    "        \n",
    "        # Save the dataset to a CSV file\n",
    "        df.to_csv(output_csv_file, index=False)\n",
    "        \n",
    "        print(f\"\\nDataset created successfully with {len(df)} samples.\")\n",
    "        print(f\"Saved to '{output_csv_file}'\")\n",
    "        \n",
    "        # Display the first few rows and the shape of the DataFrame\n",
    "        print(\"\\nDataset Head:\")\n",
    "        print(df.head())\n",
    "        print(\"\\nDataset Shape:\")\n",
    "        print(df.shape)\n",
    "        \n",
    "    else:\n",
    "        print(\"\\nNo data was processed. The dataset is empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d98f741",
   "metadata": {},
   "source": [
    "### Key Bindings Configuration\n",
    "\n",
    "In addition to the dataset, a `key_bindings_default.json` file is generated. This file maps the detected gestures to specific keyboard actions. You will need to manually edit this file to configure the desired key bindings.\n",
    "\n",
    "For each gesture, you can specify:\n",
    "- `keys`: A list of keyboard keys to be triggered. For example: `[\"ctrl\", \"c\", \"up\", \"right\"]`.\n",
    "- `behavior`: The action to perform with the keys. This can be one of two values:\n",
    "    - `\"press\"`: Simulates a quick press and release of the keys (e.g., for typing a character).\n",
    "    - `\"hold\"`: Simulates pressing and holding the keys down. The keys will be released when the gesture is no longer detected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
